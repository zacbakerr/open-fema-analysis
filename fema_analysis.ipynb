{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12egBEvMZoygGCAXsEI2B0iOYTlSZDdiI",
      "authorship_tag": "ABX9TyMAvKuX2M97oR5WC1rvApOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacbakerr/open-fema-analysis/blob/main/fema_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AZ6XUs4W-dDi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for conversion between datasets that use different notation\n",
        "\n",
        "state_abbreviations = {\n",
        "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
        "    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
        "    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
        "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
        "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
        "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
        "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
        "    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
        "    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
        "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
        "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',\n",
        "    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
        "    'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
        "}\n",
        "\n",
        "def get_state_name(abbreviation):\n",
        "    return state_abbreviations.get(abbreviation.upper(), 'Unknown')"
      ],
      "metadata": {
        "id": "Jpd5AkOKKykp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map each disaster number to the type of disaster it is\n",
        "disaster_types = dict()\n",
        "declarations = pd.read_csv(\"drive/MyDrive/Research/FEMA/data/DisasterDeclarationsSummaries.csv\")\n",
        "for index, disasterNumer in enumerate(declarations[\"disasterNumber\"]):\n",
        "  disaster_types[disasterNumer] = str(declarations[\"incidentType\"][index])\n",
        "\n",
        "# map each county to the percent of white people it has\n",
        "county_to_white_percentage = dict()\n",
        "race = pd.read_csv(\"drive/MyDrive/Research/FEMA/data/race.csv\")\n",
        "for index, county in enumerate(race[\"NAME\"]):\n",
        "  if \"Geographic Area Name\" in county: continue\n",
        "  split = county.split(\", \")\n",
        "  if \"County\" in split[0]: split[0] = split[0].replace(\" County\", \"\")\n",
        "  county_to_white_percentage[split[0] + \", \" + split[1]] = (int(race[\"P1_003N\"][index]) / int(race[\"P1_001N\"][index])) * 100\n",
        "\n",
        "# map each county to its median income\n",
        "county_to_income = dict()\n",
        "census = pd.read_csv(\"drive/MyDrive/Research/FEMA/data/income.csv\")\n",
        "for index, county in enumerate(census[\"NAME\"]):\n",
        "  if \"Geographic Area Name\" in county: continue\n",
        "  split = county.split(\", \")\n",
        "  if \"County\" in split[0]: split[0] = split[0].replace(\" County\", \"\")\n",
        "  # some counties dont have income data\n",
        "  if census[\"S1901_C01_012E\"][index] == \"-\": county_to_income[split[0] + \", \" + split[1]] = 30,000\n",
        "  else: county_to_income[split[0] + \", \" + split[1]] = int(census[\"S1901_C01_012E\"][index])\n",
        "\n",
        "# map each county to population\n",
        "county_to_population = dict()\n",
        "census = pd.read_csv(\"drive/MyDrive/Research/FEMA/data/vulnerability.csv\")\n",
        "for index, county in enumerate(census[\"NAME\"]):\n",
        "  if \"Geographic Area Name\" in county: continue\n",
        "  split = county.split(\", \")\n",
        "  if \"County\" in split[0]: split[0] = split[0].replace(\" County\", \"\")\n",
        "  # some counties dont have income data\n",
        "  county_to_population[split[0] + \", \" + split[1]] = int(census[\"POPUNI\"][index])"
      ],
      "metadata": {
        "id": "vcw5W1ClE90r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and filter data\n",
        "\n",
        "owners_data = pd.read_csv('drive/MyDrive/Research/FEMA/data/HousingAssistanceOwners.csv', delimiter=',')\n",
        "owners_data.columns = owners_data.columns.str.strip()\n",
        "\n",
        "states = [\"FL\", \"NC\", \"SC\"]\n",
        "key_disaster_types = [\"FLood\", \"Hurricane\"]\n",
        "\n",
        "filtered_data = owners_data[owners_data[\"state\"].isin(states)]\n",
        "filtered_data = filtered_data[filtered_data[\"disasterNumber\"].map(disaster_types).isin(key_disaster_types)]\n",
        "\n",
        "# create dictionary of total county damage\n",
        "\n",
        "total_county_damage = dict()\n",
        "for index, row in filtered_data.iterrows():\n",
        "  if row[\"county\"] + \", \" + row[\"state\"] not in total_county_damage:\n",
        "    total_county_damage[row[\"county\"] + \", \" + row[\"state\"]] = float(row[\"totalDamage\"])\n",
        "  else:\n",
        "    total_county_damage[row[\"county\"] + \", \" + row[\"state\"]] += float(row[\"totalDamage\"])\n",
        "\n",
        "# find the county with the max damage\n",
        "max(total_county_damage, key=lambda k: total_county_damage[k])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "j40blFTPOFvH",
        "outputId": "a19c6e02-c2e3-424f-8b72-3bab80fdbe07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-92675b8bd3a4>:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  owners_data = pd.read_csv('drive/MyDrive/Research/FEMA/data/HousingAssistanceOwners.csv', delimiter=',')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Lee (County), FL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in FEMA Individual Assistance Dataset (140,249 rows)\n",
        "owners_data = pd.read_csv('drive/MyDrive/Research/FEMA/data/HousingAssistanceOwners.csv', delimiter=',')\n",
        "owners_data.columns = owners_data.columns.str.strip()\n",
        "data = owners_data\n",
        "\n",
        "# add income and white percentage as columns to our filtered data\n",
        "data['county_state'] = data.apply(lambda row: row[\"county\"].replace(\" (County)\", \"\") + \", \" + get_state_name(row[\"state\"]), axis=1)\n",
        "\n",
        "# Add additional columns for white percentage and median income\n",
        "data['white_percentage'] = data['county_state'].map(county_to_white_percentage)\n",
        "data['median_income'] = data['county_state'].map(county_to_income)\n",
        "data['population'] = data['county_state'].map(county_to_population)\n",
        "\n",
        "# look at southern coast: TX, LA, MS, AL, FL (38,897 rows)\n",
        "entriesPerState = data[\"state\"].value_counts()\n",
        "filtered_data = data[data['state'].isin([\"TX\", \"MS\", \"AL\", \"GA\", \"FL\", \"LA\"])]\n",
        "\n",
        "# look at floods and hurricans (26,365 rows)\n",
        "filtered_data = filtered_data[\n",
        "    filtered_data[\"disasterNumber\"].map(disaster_types).isin([\"Flood\", \"Hurricane\"])\n",
        "]\n",
        "\n",
        "# look at disasters where averageFemaInspectedDamage was above $1,500 (6,156  rows) (4.4% of original row count)\n",
        "filtered_data = filtered_data[filtered_data['averageFemaInspectedDamage'] > 1500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LGn45iRJ0Ue",
        "outputId": "53bf9154-4af8-4710-c3c6-f6d38b79338b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-66821258db7c>:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  owners_data = pd.read_csv('drive/MyDrive/Research/FEMA/data/HousingAssistanceOwners.csv', delimiter=',')\n"
          ]
        }
      ]
    }
  ]
}